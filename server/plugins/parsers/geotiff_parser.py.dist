#!/usr/bin/env python3
"""
FILE:  geotiff_parser.py

USAGE:  geotiff_parser.py [-h] [-v+] <dataFile>

DESCRIPTION:  Parse the supplied geotiff file and return the json-
    formatted string used by OpenVDM as part of it's Data dashboard.

  OPTIONS:  [-h] Return the help message.
            [-v+] Increase verbosity (default: warning)
            <dataFile> Full or relative path of the data file to process.

REQUIREMENTS:  Python3.10
               Python Modules:
                   GDAL==3.10.3

     BUGS:
    NOTES:
   AUTHOR:  Webb Pinner
  VERSION:  2.10
  CREATED:  2016-08-29
 REVISION:  2025-04-12
"""

import os
import logging
import shutil
import subprocess
import sys
import tempfile
from os.path import dirname, realpath
from osgeo import gdal

sys.path.append(dirname(dirname(dirname(dirname(realpath(__file__))))))

from server.lib.openvdm_plugin import OpenVDMParser

class GeoTIFFParser(OpenVDMParser):
    """
    Custom OpenVDM file parser
    """

    def __init__(self, use_openvdm_api=False, output_dir=None):
        super().__init__(use_openvdm_api=use_openvdm_api)

        if output_dir is not None and not os.path.isdir(output_dir):
            raise FileNotFoundError("Output directory does not exist")

        self.output_dir = output_dir
        self.tile_dir = None

    def process_file(self, filepath): # pylint: disable=too-many-locals,too-many-branches,too-many-statements
        """
        Process the provided file
        """

        logging.debug("Parsing data file...")

        directoryname, filename = os.path.split(filepath)
        label = os.path.splitext(filename)[0]

        if self.output_dir is None and self.openvdm is not None:
            # parse the filepath to get the name of the file without the file extension
            data_warehouse_config = self.openvdm.get_shipboard_data_warehouse_config()
            logging.debug(self.openvdm.get_required_extra_directory_by_name("Dashboard_Data"))
            dashboard_data_dir = self.openvdm.get_required_extra_directory_by_name("Dashboard_Data")['destDir']
            cruise_id = self.openvdm.get_cruise_id()

            collection_system_dir = directoryname.replace(os.path.join(data_warehouse_config['shipboardDataWarehouseBaseDir'], cruise_id), '').lstrip('/')
            self.output_dir = os.path.join(data_warehouse_config['shipboardDataWarehouseBaseDir'], cruise_id, dashboard_data_dir, collection_system_dir)
            self.tile_dir = cruise_id + '/' + dashboard_data_dir + '/' + collection_system_dir + '/' + label

        elif self.output_dir is None:
            self.output_dir = directoryname
            self.tile_dir = os.path.join(directoryname, label)

        else:
            self.tile_dir = os.path.join(self.output_dir, label)

        # Directory where the tiles will go.
        tilepath = os.path.join(self.output_dir, label)

        # Create temp directory
        tmpdir = tempfile.mkdtemp()

        ll_filepath = os.path.join(tmpdir, label + "_LL.tif")
        vrt_filepath = os.path.join(tmpdir, 'temp.vrt')

        t_srs_options = "+proj=latlong +datum=WGS84"

        command = ['gdalwarp', '-t_srs', t_srs_options, filepath, ll_filepath]
        logging.debug("Command: %s", ' '.join(command))
        subprocess.run(command, capture_output=True, check=False)

        # open the ll geoTiff
        ll_tiff = gdal.Open(ll_filepath)

        # process the geoTiff
        width = ll_tiff.RasterXSize
        height = ll_tiff.RasterYSize
        gt_tiff = ll_tiff.GetGeoTransform()

        # calculate the bounds of the geoTiff
        minx = gt_tiff[0]
        miny = gt_tiff[3] + width*gt_tiff[4] + height*gt_tiff[5]
        maxx = gt_tiff[0] + width*gt_tiff[1] + height*gt_tiff[2]
        maxy = gt_tiff[3]

        command = ['gdal_translate', '-of', 'vrt', ll_filepath, vrt_filepath]
        logging.debug("Command: %s", ' '.join(command))
        subprocess.run(command, capture_output=True, check=False)

        command = ['gdal2tiles.py', '-v', '--profile=mercator', '--zoom=5-12', '--webviewer=none', vrt_filepath, tilepath]
        logging.debug("Command: %s", ' '.join(command))
        subprocess.run(command, capture_output=True, check=False)

        shutil.rmtree(tmpdir)

        logging.debug("Finished parsing data file")

        logging.debug("Tabulating statistics...")
        self.add_geobounds_stat([minx,miny,maxx,maxy])

        logging.debug("Building visualization data...")

        visualizer_data_obj = {
            "label": label,
            "tileDirectory": self.tile_dir,
            "mapBounds":str(minx) + "," + str(miny) + "," + str(maxx) + "," + str(maxy)
        }
        self.add_visualization_data(visualizer_data_obj)


# -------------------------------------------------------------------------------------
# Required python code for running the script as a stand-alone utility
# -------------------------------------------------------------------------------------
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='Parse GeoTiff image data')
    parser.add_argument('-v', '--verbosity', dest='verbosity',
                        default=0, action='count',
                        help='Increase output verbosity')
    parser.add_argument('--outputDir', metavar='outputDir', default=None,
                        help='where to save the output tiles')
    parser.add_argument('dataFile', metavar='dataFile',
                        help='the raw data file to process')

    parsed_args = parser.parse_args()

    ############################
    # Set up logging before we do any other argument parsing (so that we
    # can log problems with argument parsing).

    LOGGING_FORMAT = '%(asctime)-15s %(levelname)s - %(message)s'
    logging.basicConfig(format=LOGGING_FORMAT)

    LOG_LEVELS = {0: logging.WARNING, 1: logging.INFO, 2: logging.DEBUG}
    parsed_args.verbosity = min(parsed_args.verbosity, max(LOG_LEVELS))
    logging.getLogger().setLevel(LOG_LEVELS[parsed_args.verbosity])

    ovdm_parser = GeoTIFFParser(output_dir=parsed_args.outputDir)

    try:
        logging.info("Processing file: %s", parsed_args.dataFile)
        ovdm_parser.process_file(parsed_args.dataFile)
        print(ovdm_parser.to_json())
        logging.info("Done!")
    except Exception as err:
        logging.error(str(err))
        raise err
